{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f181f07",
   "metadata": {},
   "source": [
    "Uncomment if you are using colab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614508b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pymorphy2==0.9.1\n",
    "# !pip install gensim==4.1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d0b7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import Dict, Iterable, List\n",
    "\n",
    "import gensim\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly\n",
    "import pymorphy2\n",
    "from IPython.display import display\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tabulate import tabulate\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020643ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "DATA_PATH = \"./data/w2v_dataset.csv.zip\"\n",
    "EVAL_PATH = \"./data/ru_simlex965.tsv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e764af",
   "metadata": {},
   "source": [
    "Uncomment if you are using colab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55475f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir ./data\n",
    "# !wget https://raw.githubusercontent.com/vadim0912/ML2023/main/lecture08/data/w2v_dataset.csv.zip -O $DATA_PATH\n",
    "# !wget https://raw.githubusercontent.com/vadim0912/ML2023/main/lecture08/data/ru_simlex965.tsv -O $EVAL_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5998e5fe",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d56a7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876edfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sentence.str.len().hist(bins=200);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ad4a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.language.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd8895c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d476c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = df.sentence.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c52011d",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc43e9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "char2count = df.sentence.apply(lambda x: list(x.lower())).explode().value_counts()\n",
    "\n",
    "\"\".join(char2count.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9edd1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text: str) -> List[str]:\n",
    "    return re.findall(\"[оаеитнсврмлкдпузябгчіьыжхйшцющъoэфєёї]+\", text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf76d4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_set = set(nltk.corpus.stopwords.words(\"russian\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7231b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "lemmatizer_cache = {}\n",
    "\n",
    "\n",
    "def lemmatize(token: str) -> str:\n",
    "    if lemmatizer.word_is_known(token):\n",
    "        if token not in lemmatizer_cache:\n",
    "            lemmatizer_cache[token] = lemmatizer.parse(token)[0].normal_form\n",
    "        return lemmatizer_cache[token]\n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e731bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sentence_dataset(documents: Iterable[str]) -> List[List[str]]:\n",
    "    tokenized_sentences = []\n",
    "    for document in tqdm_notebook(documents):\n",
    "        for sentence in nltk.sent_tokenize(document):\n",
    "            lemmatized_tokens = [lemmatize(token) for token in tokenize(sentence)]\n",
    "            tokenized_sentences.append(\n",
    "                [token for token in lemmatized_tokens if token not in stopword_set]\n",
    "            )\n",
    "    return tokenized_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba7f875",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_dataset = prepare_sentence_dataset(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ddf676",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sentence_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936e9cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cab241",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_dataset[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdaaf37",
   "metadata": {},
   "source": [
    "# Word2Vec training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63246d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = gensim.models.Word2Vec(\n",
    "    vector_size=100, sg=0, window=5, min_count=5, negative=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e026e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec.build_vocab(sentence_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3055e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(word2vec.wv.index_to_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb10b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "word2vec.train(sentence_dataset, total_examples=word2vec.corpus_count, epochs=30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26aabff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec.wv.most_similar(\"мама\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd79ee33",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_words = [\"можливість\", \"чоловік\", \"возможность\", \"мужчина\"]\n",
    "\n",
    "for word in test_words:\n",
    "    print(word)\n",
    "    print(\n",
    "        tabulate(\n",
    "            word2vec.wv.most_similar(word),\n",
    "            tablefmt=\"orgtbl\",\n",
    "            headers=(\"neighbor\", \"score\"),\n",
    "        ),\n",
    "        end=\"\\n\\n\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0c72a0",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7851626",
   "metadata": {},
   "outputs": [],
   "source": [
    "index2word = np.array(word2vec.wv.index_to_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afed37d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = word2vec.wv.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbaf0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71da920d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = np.random.randint(low=0, high=index2word.size, size=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d777007",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_reduced = TSNE(random_state=SEED, n_components=2).fit_transform(\n",
    "    embeddings[ids]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ed9106",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tsne_embeddings(embeddings: np.ndarray, annotations: np.ndarray) -> None:\n",
    "    trace = plotly.graph_objs.Scattergl(\n",
    "        x=embeddings[:, 0],\n",
    "        y=embeddings[:, 1],\n",
    "        name=\"Embedding\",\n",
    "        mode=\"markers\",\n",
    "        marker={\"colorscale\": \"Viridis\", \"size\": 6, \"line\": {\"width\": 0.5}, \"opacity\": 0.75},\n",
    "        text=annotations,\n",
    "    )\n",
    "\n",
    "    layout = {\n",
    "        \"title\": \"Word2Vec 2D TSNE Embeddings\",\n",
    "        \"yaxis\": {\"zeroline\": False},\n",
    "        \"xaxis\": {\"zeroline\": False},\n",
    "        \"hovermode\": \"closest\",\n",
    "        \"width\": 800,\n",
    "        \"height\": 800,\n",
    "    }\n",
    "\n",
    "    display(plotly.graph_objs.Figure(data=[trace], layout=layout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12de88bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tsne_embeddings(embeddings_reduced, index2word[ids])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df4b52f",
   "metadata": {},
   "source": [
    "# Sentence Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37ef37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_text(\n",
    "    text: Iterable[str], word2index: Dict[str, int], word_embeddings: np.ndarray\n",
    ") -> np.ndarray:\n",
    "    embs = np.array(\n",
    "        [\n",
    "            word_embeddings[word2index[word]]\n",
    "            for word in text\n",
    "            if word in word2index and word not in stopword_set\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    if embs.shape[0] > 0:\n",
    "        return embs.mean(0, keepdims=True)\n",
    "    else:\n",
    "        return np.zeros((1, word_embeddings.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55feb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2index = word2vec.wv.key_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa63365",
   "metadata": {},
   "outputs": [],
   "source": [
    "talks = [\n",
    "    [lemmatize(token) for token in tokenize(text) if token not in stopword_set]\n",
    "    for text in corpus\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc95923e",
   "metadata": {},
   "outputs": [],
   "source": [
    "talk2vec = np.concatenate([embed_text(talk, word2index, embeddings) for talk in talks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c8cf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = np.random.randint(low=0, high=index2word.size, size=10_000)\n",
    "\n",
    "talk2vec_reduced = TSNE(n_components=2, random_state=SEED).fit_transform(talk2vec[ids])\n",
    "\n",
    "plot_tsne_embeddings(talk2vec_reduced, df.sentence.values[ids])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acf83e2",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98174066",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_set = pd.read_csv(EVAL_PATH, sep=\"\\t\")\n",
    "\n",
    "eval_set.columns = [\"word1\", \"word2\", \"human_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07da3ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = eval_set.apply(\n",
    "    lambda row: (row[\"word1\"] in word2index) & (row[\"word2\"] in word2index), axis=1\n",
    ")\n",
    "\n",
    "eval_set = eval_set[mask].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ddcbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_set[\"model_score\"] = eval_set.apply(\n",
    "    lambda row: cosine_similarity(\n",
    "        embeddings[[word2index[row[\"word1\"]]]], embeddings[[word2index[row[\"word2\"]]]]\n",
    "    )[0][0],\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f474a98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(eval_set[\"model_score\"], eval_set[\"human_score\"], alpha=0.8);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5533690",
   "metadata": {},
   "outputs": [],
   "source": [
    "pearsonr(eval_set[\"model_score\"], eval_set[\"human_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3ac458",
   "metadata": {},
   "outputs": [],
   "source": [
    "spearmanr(eval_set[\"model_score\"], eval_set[\"human_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6409b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_set.sort_values(\"human_score\").tail(20).style.background_gradient(\n",
    "    subset=[\"model_score\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ec88eb",
   "metadata": {},
   "source": [
    "# Appendix\n",
    "* FastText: https://arxiv.org/abs/1607.01759\n",
    "* Byte Pair Encoding:\n",
    "    * https://arxiv.org/abs/1508.07909\n",
    "    * https://www.derczynski.com/papers/archive/BPE_Gage.pdf\n",
    "* Stop Using Word2Vec: https://multithreaded.stitchfix.com/blog/2017/10/18/stop-using-word2vec/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e589e04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
